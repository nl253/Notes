# Cognitive Neural Networks

-   neural networks will be harder to train if the inputs are similar
-   a weight of 0 means that the neuron will ignore the input
-   a negative weight means that the neuron will not only ignore the
    input but will choose those patterns that don't cause this
    activation (i.e.Â the neuron wants that feature to be off)
-   neurons won't fire unless they go through some threshold ($\theta$)
    -- it acts as a barrier
-   once a neuron has fired it will temporarily go below the resting
    potential -- as a result it cannot fire *right after*

The Jennefer Anniston neuron is at the end of the visual processing
pathway. This is because it requires the detection of basic shapes,
light etc. and many other, more sophisticated and fine features.

## Pre-Synaptic vs Post-Synaptic

Relative to a synapse -- a neuron can be either pre-synaptic if it comes
before or post- if it comes after.

## Questions

1.  What is the optimal distribution to draw random initial weights
    from?

## Glossary

Synapse
:   is the gap between neurons

Membrane Potential
:   difference in charge between the inside and outside of a neuron

## References




